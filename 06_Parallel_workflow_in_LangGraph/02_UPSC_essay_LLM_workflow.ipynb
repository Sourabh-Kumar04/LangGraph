{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "830e48aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "from typing import TypedDict, Annotated\n",
    "from pydantic import Field, BaseModel\n",
    "import operator\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Get API key from environment variable\n",
    "hf_api_key = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e5da3a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema\n",
    "class EvaluationSchema(BaseModel):\n",
    "\n",
    "    feedback: str = Field(description=\"Detailed feedback for the essay\")\n",
    "    score: int = Field(description=\"Score out of 10\", ge=0, le=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bf0615d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to JSON schema (Pydantic v2)\n",
    "schema = EvaluationSchema.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5219325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structured Output Model\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"Qwen/Qwen3-Next-80B-A3B-Instruct\",\n",
    "    # repo_id=\"tiiuae/falcon-7b-instruct\",\n",
    "    task=\"task-generation\",\n",
    "    # huggingfacehub_api_token=hf_api_key\n",
    "    huggingfacehub_api_token=os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    ")\n",
    "\n",
    "model = ChatHuggingFace(llm=llm)\n",
    "\n",
    "# import os\n",
    "# from dotenv import load_dotenv\n",
    "# from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# load_dotenv()\n",
    "\n",
    "# # Add to .env: GOOGLE_API_KEY=your-gemini-key\n",
    "# model = ChatGoogleGenerativeAI(\n",
    "#     model=\"gemini-1.5-flash\",\n",
    "#     google_api_key=os.getenv(\"GOOGLE_API_KEY\")\n",
    "# )\n",
    "\n",
    "# structured_model = model.with_structured_output(schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "20a223f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_model = model.with_structured_output(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3bf364e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "essay = \"\"\"\n",
    "# 🌟 AI and Its Future in India\n",
    "\n",
    "## 📌 Current Landscape\n",
    "\n",
    "* **Rapid Growth**: India is among the **top 5 countries** in AI research publications.\n",
    "* **Government Push**: Initiatives like **Digital India, National AI Strategy (NITI Aayog), and IndiaAI Mission** aim to build AI as a core pillar of development.\n",
    "* **Startups & Industry**: Over **5,000+ AI startups** in India, focusing on healthtech, fintech, edtech, and agritech.\n",
    "* **Skilled Workforce**: India produces the **largest pool of STEM graduates** annually, making it a hub for AI talent.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔑 Key Application Areas\n",
    "\n",
    "1. **Healthcare 🏥**\n",
    "\n",
    "   * AI in medical imaging, disease prediction, and telemedicine.\n",
    "   * Affordable AI-driven solutions for rural healthcare.\n",
    "\n",
    "2. **Agriculture 🌾**\n",
    "\n",
    "   * Precision farming with drones & AI sensors.\n",
    "   * Predictive analytics for weather & crop yield.\n",
    "   * Reducing supply chain inefficiencies.\n",
    "\n",
    "3. **Education 🎓**\n",
    "\n",
    "   * Personalized learning platforms with AI tutors.\n",
    "   * Local-language learning tools powered by NLP.\n",
    "   * Bridging urban–rural education gaps.\n",
    "\n",
    "4. **Finance & Banking 💰**\n",
    "\n",
    "   * Fraud detection & risk management.\n",
    "   * AI-driven credit scoring for underserved communities.\n",
    "   * Chatbots for customer support in regional languages.\n",
    "\n",
    "5. **Governance & Smart Cities 🏙️**\n",
    "\n",
    "   * Traffic management with AI vision systems.\n",
    "   * Digital governance and citizen services.\n",
    "   * Disaster response and resource optimization.\n",
    "\n",
    "---\n",
    "\n",
    "## 🚀 Opportunities Ahead\n",
    "\n",
    "* **Demographic Advantage**: Young, tech-savvy population ready to adopt AI.\n",
    "* **Data Wealth**: India generates massive datasets — essential for training AI systems.\n",
    "* **Local Language AI**: A huge opportunity lies in **developing AI for Indian languages** (22 official + 100+ spoken).\n",
    "* **Global AI Hub Potential**: India can become an outsourcing + innovation hub for AI solutions like it did for IT.\n",
    "\n",
    "---\n",
    "\n",
    "## ⚠️ Challenges to Overcome\n",
    "\n",
    "* **Data Privacy & Security**: Need stronger AI governance and data protection laws.\n",
    "* **Skill Gap**: Despite talent, advanced AI expertise (like deep learning, AGI research) is limited.\n",
    "* **Infrastructure**: Limited GPU/data center capacity compared to the US/China.\n",
    "* **Ethical Concerns**: Job displacement, bias in algorithms, and misuse of AI.\n",
    "\n",
    "---\n",
    "\n",
    "## 🌈 The Future Vision (Next 10–20 years)\n",
    "\n",
    "* **Inclusive AI**: Affordable AI-powered healthcare and education for rural India.\n",
    "* **AI in Democracy**: Smarter governance, transparent systems, AI-driven policymaking.\n",
    "* **Economic Boost**: AI could add **$1 trillion+ to India’s economy by 2035** (Accenture report).\n",
    "* **AI Sovereignty**: Development of **indigenous AI models** trained on Indian data, culture, and languages.\n",
    "* **Human–AI Collaboration**: Focus on AI as a **copilot for humans**, not a replacement.\n",
    "\n",
    "---\n",
    "\n",
    "📌 **Takeaway:**\n",
    "AI has the potential to **redefine India’s growth story**, much like IT did in the 90s. With the right balance of **policy, innovation, and ethics**, India can lead the **AI revolution** not just for itself, but for the **Global South**. 🌍🇮🇳\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feedback': \"The essay is exceptionally well-structured, clearly organized, and highly informative. It effectively uses headings and bullet points to enhance readability and logical flow. The language is precise, formal, and appropriate for an academic or policy-oriented audience. Technical terms are used accurately (e.g., NLP, AGI, precision farming), and the tone remains consistent throughout. The essay demonstrates strong command of vocabulary, syntax, and coherence. Minor improvements could include varying sentence structure slightly to avoid repetitive bullet-point phrasing and ensuring all acronyms are spelled out on first use (e.g., NITI Aayog could be introduced as 'National Institution for Transforming India Aayog'). However, these are negligible given the overall excellence. The conclusion is powerful and ties the essay together with a compelling vision. This is a model piece of writing.\",\n",
       " 'score': 10}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = f\"Evaluate the language quality of the following essay and provide a feedback and assign a score out of 10 \\n{essay}\"\n",
    "\n",
    "output = structured_model.invoke(prompt)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5fbe4fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The essay is exceptionally well-structured, clearly organized, and highly informative. It effectively uses headings and bullet points to enhance readability and logical flow. The language is precise, formal, and appropriate for an academic or policy-oriented audience. Technical terms are used accurately (e.g., NLP, AGI, precision farming), and the tone remains consistent throughout. The essay demonstrates strong command of vocabulary, syntax, and coherence. Minor improvements could include varying sentence structure slightly to avoid repetitive bullet-point phrasing and ensuring all acronyms are spelled out on first use (e.g., NITI Aayog could be introduced as 'National Institution for Transforming India Aayog'). However, these are negligible given the overall excellence. The conclusion is powerful and ties the essay together with a compelling vision. This is a model piece of writing.\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(output[\"feedback\"])\n",
    "print(output[\"score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UPSCState(TypedDict):\n",
    "\n",
    "    essay_text: str\n",
    "\n",
    "    language_feedback: str\n",
    "    analysis_feedback: str\n",
    "    clarity_feedback: str\n",
    "\n",
    "    overall_feedback: str\n",
    "\n",
    "    individual_scores: Annotated[list[int], operator.add]\n",
    "    avg_score: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6ecf5e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_language(state: UPSCState) -> UPSCState:\n",
    "    \n",
    "    prompt = f\"Evaluate the language quality of the following essay and provide a feedback and assign a score out of 10 \\n{state['essay_text']}\"\n",
    "    output = structured_model.invoke(prompt)\n",
    "    print(output)\n",
    "\n",
    "    return {'language_feedback': output[\"feedback\"], 'individual_scores': [output[\"score\"]]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4069cfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_analysis(state: UPSCState) -> UPSCState:\n",
    "    \n",
    "    prompt = f\"Evaluate the depth analysis of the following essay and provide a feedback and assign a score out of 10 \\n{state['essay_text']}\"\n",
    "    output = structured_model.invoke(prompt)\n",
    "\n",
    "    return {'analysis_feedback': output[\"feedback\"], 'individual_scores': [output[\"score\"]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "231789bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_thought(state: UPSCState) -> UPSCState:\n",
    "\n",
    "    prompt = f\"Evaluate the clarity of thought of the following essay and provide a feedback and assign a score out of 10 \\n{state['essay_text']}\"\n",
    "    output = structured_model.invoke(prompt)\n",
    "\n",
    "    return {'clarity_feedback': output[\"feedback\"], 'individual_scores': [output[\"score\"]]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5d9ba15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_evaluation(state: UPSCState) -> UPSCState:\n",
    "    # Fixed: Use correct state keys\n",
    "    prompt = f\"\"\"Based on the following feedback, create a summarized evaluation:\n",
    "        \n",
    "    Language feedback: {state['language_feedback']}\n",
    "    Analysis feedback: {state['analysis_feedback']} \n",
    "    Clarity feedback: {state['clarity_feedback']}\n",
    "\n",
    "    Provide a comprehensive overall assessment.\n",
    "    \"\"\"\n",
    "    \n",
    "    overall_feedback = structured_model.invoke(prompt)\n",
    "    avg_score = sum(state['individual_scores']) / len(state['individual_scores'])\n",
    "    \n",
    "    return {'overall_feedback': overall_feedback, 'avg_score': avg_score}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(UPSCState)\n",
    "\n",
    "# nodes\n",
    "graph.add_node('evaluate_language', evaluate_language)\n",
    "graph.add_node('evaluate_analysis', evaluate_analysis)\n",
    "graph.add_node('evaluate_thought', evaluate_thought)\n",
    "\n",
    "graph.add_node('final_evaluation', final_evaluation)\n",
    "\n",
    "# edges\n",
    "graph.add_edge(START, 'evaluate_language')\n",
    "graph.add_edge(START, 'evaluate_analysis')\n",
    "graph.add_edge(START, 'evaluate_thought')\n",
    "\n",
    "graph.add_edge('evaluate_language', 'final_evaluation')\n",
    "graph.add_edge('evaluate_analysis', 'final_evaluation')\n",
    "graph.add_edge('evaluate_thought', 'final_evaluation')\n",
    "\n",
    "graph.add_edge('final_evaluation', END)\n",
    "\n",
    "workflow = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "db3cd27e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to reach https://mermaid.ink/ API while trying to render your graph. Status code: 502.\n\nTo resolve this issue:\n1. Check your internet connection and try again\n2. Try with higher retry settings: `draw_mermaid_png(..., max_retries=5, retry_delay=2.0)`\n3. Use the Pyppeteer rendering method which will render your graph locally in a browser: `draw_mermaid_png(..., draw_method=MermaidDrawMethod.PYPPETEER)`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Academics/Generative AI by CampusX/.venv/lib/python3.12/site-packages/IPython/core/formatters.py:1036\u001b[39m, in \u001b[36mMimeBundleFormatter.__call__\u001b[39m\u001b[34m(self, obj, include, exclude)\u001b[39m\n\u001b[32m   1033\u001b[39m     method = get_real_method(obj, \u001b[38;5;28mself\u001b[39m.print_method)\n\u001b[32m   1035\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1036\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43minclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1037\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1038\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Academics/Generative AI by CampusX/.venv/lib/python3.12/site-packages/langgraph/pregel/main.py:758\u001b[39m, in \u001b[36mPregel._repr_mimebundle_\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    754\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_repr_mimebundle_\u001b[39m(\u001b[38;5;28mself\u001b[39m, **kwargs: Any) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m    755\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Mime bundle used by Jupyter to display the graph\"\"\"\u001b[39;00m\n\u001b[32m    756\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m    757\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtext/plain\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mself\u001b[39m),\n\u001b[32m--> \u001b[39m\u001b[32m758\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mimage/png\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw_mermaid_png\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    759\u001b[39m     }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Academics/Generative AI by CampusX/.venv/lib/python3.12/site-packages/langchain_core/runnables/graph.py:695\u001b[39m, in \u001b[36mGraph.draw_mermaid_png\u001b[39m\u001b[34m(self, curve_style, node_colors, wrap_label_n_words, output_file_path, draw_method, background_color, padding, max_retries, retry_delay, frontmatter_config)\u001b[39m\n\u001b[32m    687\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrunnables\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph_mermaid\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m draw_mermaid_png\n\u001b[32m    689\u001b[39m mermaid_syntax = \u001b[38;5;28mself\u001b[39m.draw_mermaid(\n\u001b[32m    690\u001b[39m     curve_style=curve_style,\n\u001b[32m    691\u001b[39m     node_colors=node_colors,\n\u001b[32m    692\u001b[39m     wrap_label_n_words=wrap_label_n_words,\n\u001b[32m    693\u001b[39m     frontmatter_config=frontmatter_config,\n\u001b[32m    694\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m695\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw_mermaid_png\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdraw_method\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdraw_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    699\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Academics/Generative AI by CampusX/.venv/lib/python3.12/site-packages/langchain_core/runnables/graph_mermaid.py:294\u001b[39m, in \u001b[36mdraw_mermaid_png\u001b[39m\u001b[34m(mermaid_syntax, output_file_path, draw_method, background_color, padding, max_retries, retry_delay)\u001b[39m\n\u001b[32m    288\u001b[39m     img_bytes = asyncio.run(\n\u001b[32m    289\u001b[39m         _render_mermaid_using_pyppeteer(\n\u001b[32m    290\u001b[39m             mermaid_syntax, output_file_path, background_color, padding\n\u001b[32m    291\u001b[39m         )\n\u001b[32m    292\u001b[39m     )\n\u001b[32m    293\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m draw_method == MermaidDrawMethod.API:\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m     img_bytes = \u001b[43m_render_mermaid_using_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    301\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    302\u001b[39m     supported_methods = \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join([m.value \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m MermaidDrawMethod])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Academics/Generative AI by CampusX/.venv/lib/python3.12/site-packages/langchain_core/runnables/graph_mermaid.py:451\u001b[39m, in \u001b[36m_render_mermaid_using_api\u001b[39m\u001b[34m(mermaid_syntax, output_file_path, background_color, file_type, max_retries, retry_delay)\u001b[39m\n\u001b[32m    446\u001b[39m     \u001b[38;5;66;03m# For other status codes, fail immediately\u001b[39;00m\n\u001b[32m    447\u001b[39m     msg = (\n\u001b[32m    448\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFailed to reach https://mermaid.ink/ API while trying to render \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    449\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33myour graph. Status code: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    450\u001b[39m     ) + error_msg_suffix\n\u001b[32m--> \u001b[39m\u001b[32m451\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (requests.RequestException, requests.Timeout) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attempt < max_retries:\n\u001b[32m    455\u001b[39m         \u001b[38;5;66;03m# Exponential backoff with jitter\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: Failed to reach https://mermaid.ink/ API while trying to render your graph. Status code: 502.\n\nTo resolve this issue:\n1. Check your internet connection and try again\n2. Try with higher retry settings: `draw_mermaid_png(..., max_retries=5, retry_delay=2.0)`\n3. Use the Pyppeteer rendering method which will render your graph locally in a browser: `draw_mermaid_png(..., draw_method=MermaidDrawMethod.PYPPETEER)`"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph at 0x77419aff68a0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feedback': \"The essay is exceptionally well-structured, clearly organized, and highly informative. The use of bullet points and emojis enhances readability without compromising professionalism. The content demonstrates a strong grasp of AI's role in India, covering current landscape, key applications, opportunities, challenges, and future vision in a balanced and comprehensive manner. Language is precise, formal, and appropriate for an academic or policy-oriented audience. Vocabulary is rich and varied (e.g., 'indigenous AI models', 'AI sovereignty', 'human-AI collaboration'), and sentence structures are sophisticated yet clear. Minor improvements could include integrating a few transitional phrases between sections for smoother flow and avoiding overuse of emojis in formal contexts, though they are acceptable in modern digital communication. No grammatical or syntactical errors are present. The conclusion effectively ties together the essay’s themes with a compelling call to action.\", 'score': 10}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'essay_text': '\\n# 🌟 AI and Its Future in India\\n\\n## 📌 Current Landscape\\n\\n* **Rapid Growth**: India is among the **top 5 countries** in AI research publications.\\n* **Government Push**: Initiatives like **Digital India, National AI Strategy (NITI Aayog), and IndiaAI Mission** aim to build AI as a core pillar of development.\\n* **Startups & Industry**: Over **5,000+ AI startups** in India, focusing on healthtech, fintech, edtech, and agritech.\\n* **Skilled Workforce**: India produces the **largest pool of STEM graduates** annually, making it a hub for AI talent.\\n\\n---\\n\\n## 🔑 Key Application Areas\\n\\n1. **Healthcare 🏥**\\n\\n   * AI in medical imaging, disease prediction, and telemedicine.\\n   * Affordable AI-driven solutions for rural healthcare.\\n\\n2. **Agriculture 🌾**\\n\\n   * Precision farming with drones & AI sensors.\\n   * Predictive analytics for weather & crop yield.\\n   * Reducing supply chain inefficiencies.\\n\\n3. **Education 🎓**\\n\\n   * Personalized learning platforms with AI tutors.\\n   * Local-language learning tools powered by NLP.\\n   * Bridging urban–rural education gaps.\\n\\n4. **Finance & Banking 💰**\\n\\n   * Fraud detection & risk management.\\n   * AI-driven credit scoring for underserved communities.\\n   * Chatbots for customer support in regional languages.\\n\\n5. **Governance & Smart Cities 🏙️**\\n\\n   * Traffic management with AI vision systems.\\n   * Digital governance and citizen services.\\n   * Disaster response and resource optimization.\\n\\n---\\n\\n## 🚀 Opportunities Ahead\\n\\n* **Demographic Advantage**: Young, tech-savvy population ready to adopt AI.\\n* **Data Wealth**: India generates massive datasets — essential for training AI systems.\\n* **Local Language AI**: A huge opportunity lies in **developing AI for Indian languages** (22 official + 100+ spoken).\\n* **Global AI Hub Potential**: India can become an outsourcing + innovation hub for AI solutions like it did for IT.\\n\\n---\\n\\n## ⚠️ Challenges to Overcome\\n\\n* **Data Privacy & Security**: Need stronger AI governance and data protection laws.\\n* **Skill Gap**: Despite talent, advanced AI expertise (like deep learning, AGI research) is limited.\\n* **Infrastructure**: Limited GPU/data center capacity compared to the US/China.\\n* **Ethical Concerns**: Job displacement, bias in algorithms, and misuse of AI.\\n\\n---\\n\\n## 🌈 The Future Vision (Next 10–20 years)\\n\\n* **Inclusive AI**: Affordable AI-powered healthcare and education for rural India.\\n* **AI in Democracy**: Smarter governance, transparent systems, AI-driven policymaking.\\n* **Economic Boost**: AI could add **\\\\ $1 trillion+ to India’s economy by 2035** (Accenture report).\\n* **AI Sovereignty**: Development of **indigenous AI models** trained on Indian data, culture, and languages.\\n* **Human–AI Collaboration**: Focus on AI as a **copilot for humans**, not a replacement.\\n\\n---\\n\\n📌 **Takeaway:**\\nAI has the potential to **redefine India’s growth story**, much like IT did in the 90s. With the right balance of **policy, innovation, and ethics**, India can lead the **AI revolution** not just for itself, but for the **Global South**. 🌍🇮🇳\\n',\n",
       " 'language_feedback': \"The essay is exceptionally well-structured, clearly organized, and highly informative. The use of bullet points and emojis enhances readability without compromising professionalism. The content demonstrates a strong grasp of AI's role in India, covering current landscape, key applications, opportunities, challenges, and future vision in a balanced and comprehensive manner. Language is precise, formal, and appropriate for an academic or policy-oriented audience. Vocabulary is rich and varied (e.g., 'indigenous AI models', 'AI sovereignty', 'human-AI collaboration'), and sentence structures are sophisticated yet clear. Minor improvements could include integrating a few transitional phrases between sections for smoother flow and avoiding overuse of emojis in formal contexts, though they are acceptable in modern digital communication. No grammatical or syntactical errors are present. The conclusion effectively ties together the essay’s themes with a compelling call to action.\",\n",
       " 'analysis_feedback': \"The essay provides a comprehensive, well-structured overview of AI's current landscape and future potential in India. It effectively highlights key areas of application (healthcare, agriculture, education, finance, governance) with concrete examples and demonstrates a clear understanding of both opportunities and challenges. The inclusion of demographic, data, and linguistic advantages adds depth, while the acknowledgment of infrastructure gaps, ethical concerns, and skill shortages shows critical thinking. The future vision section is particularly strong, linking AI to national development goals and global leadership in the Global South. The tone is confident and forward-looking, with relevant data points (e.g., 5,000+ startups, $1 trillion economic impact) enhancing credibility. Minor improvements could include citing sources for statistics and expanding slightly on policy recommendations to address challenges. Overall, this is an insightful, balanced, and compelling analysis.\",\n",
       " 'clarity_feedback': \"The essay demonstrates exceptional clarity of thought. It is logically structured, with each section building upon the previous one to present a comprehensive overview of AI's current landscape, applications, opportunities, challenges, and future vision in India. The use of bullet points and subheadings enhances readability and ensures that complex ideas are broken down digestibly. Key arguments are well-supported with specific examples (e.g., 5,000+ AI startups, Accenture’s $1 trillion projection) and contextualized within India’s socio-economic framework. The essay effectively balances optimism with realism by acknowledging challenges like data privacy, infrastructure gaps, and ethical concerns without undermining its central thesis. The conclusion ties all threads together powerfully, positioning India as a potential global leader in inclusive, ethical AI — a compelling and original insight. Language is precise, jargon is appropriately used, and cultural context is respected. No significant ambiguity or logical leaps are present.\",\n",
       " 'overall_feedback': {'feedback': \"This is an exceptional essay that demonstrates a masterful command of both content and style. Structured with clarity and precision, it offers a comprehensive, balanced, and insightful analysis of AI's role in India—covering current applications, opportunities, challenges, and a forward-looking vision with compelling evidence such as 5,000+ AI startups and the $1 trillion economic projection. The language is sophisticated, formal, and free of errors, with rich vocabulary and nuanced phrasing that elevate its academic and policy relevance. The integration of bullet points and emojis enhances accessibility without sacrificing professionalism, though minor use of transitional phrases could further improve flow. The analysis is critically robust, acknowledging structural challenges like infrastructure gaps and ethical concerns while maintaining a confident, solutions-oriented tone. The conclusion powerfully positions India as a potential global leader in inclusive and ethical AI, offering an original and impactful insight. Minor enhancements could include citing sources for statistics and expanding policy recommendations. Overall, this is a model piece of analytical writing that is informative, persuasive, and intellectually rigorous.\",\n",
       "  'score': 10},\n",
       " 'individual_scores': [9, 10, 10],\n",
       " 'avg_score': 9.666666666666666}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exectution\n",
    "initial_state = {\n",
    "    'essay_text': essay\n",
    "}\n",
    "\n",
    "workflow.invoke(initial_state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "generative-ai-by-campusx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
